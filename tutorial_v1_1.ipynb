{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for using MLflow on Puhti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will guide you through using MLflow in the Puhti computing environment, offering a streamlined and centralized approach to tracking machine learning experiments. It’s tailored for machine learning practitioners who seek an efficient way to manage and monitor their experiments.\n",
    "\n",
    "While prior experience with MLflow isn’t necessary, a basic understanding of supercomputing is recommended. We’ll explore the core components of MLflow and demonstrate their application through practical examples. You can follow along with the provided sample code or incorporate your own code into the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is MLflow?\n",
    "\n",
    "**MLflow** in an open-source tool for managing machine learning models throughout their life cycle. It has four key components that can be widely utilized, from experimenting to deploying models:\n",
    "\n",
    "- **Tracking Server** is the core component used for tracking experiments. Results can be viewed and compared through an informative user interface or API.\n",
    "\t\n",
    "- **Models** is for packaging the models in a unified format, making it easy to move and share them.\n",
    "\n",
    "- **Model Registry** provides tools for registering and versioning models. The registry can also be managed through the UI.\n",
    "\n",
    "- **Projects** is for packaging entire ML project code, enabling easy sharing and reproducibility.\n",
    "\n",
    "For more info on components visit MLflow documentation: https://mlflow.org/docs/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import mlflow\n",
    "#from mlflow.keras import log_model, save_model, autolog\n",
    "#from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/sternade/Nextcloud_Kannu/Opari/mlruns/581032223001777713', creation_time=1723792570471, experiment_id='581032223001777713', last_update_time=1723792570471, lifecycle_stage='active', name='MNIST example', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Määritellään MLflow \n",
    "\"\"\"\n",
    "\n",
    "#project_id = \"your_project_1234\"\n",
    "#mlflow.set_tracking_uri(\"/scratch/{project_id}/mlruns\")\n",
    "\n",
    "mlflow.set_tracking_uri(\"/home/sternade/Nextcloud_Kannu/Opari/mlruns\") # where artifacts and metadata is stored\n",
    "description = \"Experimenting with different models to find the best performer on MNIST.\"\n",
    "mlflow.set_experiment(\"MNIST example\") # set experiment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sternade/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: sequential_3layers\n",
      "<Sequential name=sequential, built=True>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9073 - loss: 0.3073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1080s\u001b[0m 18ms/step - accuracy: 0.9073 - loss: 0.3073 - val_accuracy: 0.9643 - val_loss: 0.1225\n",
      "Epoch 2/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 17ms/step - accuracy: 0.9656 - loss: 0.1249 - val_accuracy: 0.9668 - val_loss: 0.1375\n",
      "Epoch 3/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m709s\u001b[0m 11ms/step - accuracy: 0.9737 - loss: 0.0991 - val_accuracy: 0.9680 - val_loss: 0.1423\n",
      "Epoch 4/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0918 - val_accuracy: 0.9709 - val_loss: 0.1588\n",
      "Epoch 5/10\n",
      "\u001b[1m59994/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0793 - val_accuracy: 0.9742 - val_loss: 0.1565\n",
      "Epoch 6/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.0727 - val_accuracy: 0.9731 - val_loss: 0.1777\n",
      "Epoch 7/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0627 - val_accuracy: 0.9707 - val_loss: 0.2264\n",
      "Epoch 8/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0590 - val_accuracy: 0.9700 - val_loss: 0.2345\n",
      "Epoch 9/10\n",
      "\u001b[1m59996/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.0586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.0586 - val_accuracy: 0.9725 - val_loss: 0.2278\n",
      "Epoch 10/10\n",
      "\u001b[1m59999/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0546 - val_accuracy: 0.9749 - val_loss: 0.2214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/27 12:03:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/sternade/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 4ms/step - accuracy: 0.9749 - loss: 0.2214\n",
      "\n",
      "Test accuracy: 0.9749000072479248\n",
      "Run name: sequential_with_tanh\n",
      "<Sequential name=sequential_1, built=True>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m59994/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8949 - loss: 0.3439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 8ms/step - accuracy: 0.8949 - loss: 0.3439 - val_accuracy: 0.9564 - val_loss: 0.1467\n",
      "Epoch 2/10\n",
      "\u001b[1m59993/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9543 - loss: 0.1527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 8ms/step - accuracy: 0.9543 - loss: 0.1527 - val_accuracy: 0.9561 - val_loss: 0.1425\n",
      "Epoch 3/10\n",
      "\u001b[1m59998/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.1251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.1251 - val_accuracy: 0.9602 - val_loss: 0.1329\n",
      "Epoch 4/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9670 - loss: 0.1102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1018s\u001b[0m 17ms/step - accuracy: 0.9670 - loss: 0.1102 - val_accuracy: 0.9615 - val_loss: 0.1297\n",
      "Epoch 5/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9684 - loss: 0.1026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1257s\u001b[0m 21ms/step - accuracy: 0.9684 - loss: 0.1026 - val_accuracy: 0.9644 - val_loss: 0.1243\n",
      "Epoch 6/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1326s\u001b[0m 22ms/step - accuracy: 0.9685 - loss: 0.1024 - val_accuracy: 0.9622 - val_loss: 0.1417\n",
      "Epoch 7/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9727 - loss: 0.0897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1484s\u001b[0m 25ms/step - accuracy: 0.9727 - loss: 0.0897 - val_accuracy: 0.9633 - val_loss: 0.1300\n",
      "Epoch 8/10\n",
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9715 - loss: 0.0934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 15ms/step - accuracy: 0.9715 - loss: 0.0934 - val_accuracy: 0.9651 - val_loss: 0.1287\n",
      "Epoch 9/10\n",
      "\u001b[1m59997/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9741 - loss: 0.0841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 11ms/step - accuracy: 0.9741 - loss: 0.0841 - val_accuracy: 0.9663 - val_loss: 0.1268\n",
      "Epoch 10/10\n",
      "\u001b[1m59997/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9757 - loss: 0.0803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60000/60000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 10ms/step - accuracy: 0.9757 - loss: 0.0803 - val_accuracy: 0.9683 - val_loss: 0.1153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
      "313/313 - 2s - 6ms/step - accuracy: 0.9683 - loss: 0.1153\n",
      "\n",
      "Test accuracy: 0.9682999849319458\n"
     ]
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog(every_n_iter=1, \n",
    "                          log_models=True, \n",
    "                          log_datasets=True) # https://mlflow.org/docs/latest/python_api/mlflow.tensorflow.html\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Let's build and compile two slightly different models to compare. You can use the examples for studying or you can add your own model.\n",
    "model_1 = Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_2 = Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation='tanh'),\n",
    "        layers.Dense(64, activation='tanh'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "models = {model_1: \"sequential_3layers\", \n",
    "          model_2: \"sequential_with_tanh\"}\n",
    "\n",
    "for model, run_name in models.items():\n",
    "        \n",
    "    with mlflow.start_run(): # trigger mlflow to start tracking the run\n",
    "        mlflow.set_tag(\"mlflow.runName\", run_name)\n",
    "        print(f\"Run name: {run_name}\")\n",
    "        print(model)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=1, validation_data=(X_test, y_test))\n",
    "\n",
    "        # Sign the signature\n",
    "        #signature = infer_signature(X_train, model.predict(X_test))\n",
    "\n",
    "        # Evaluate the model\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "        #mlflow.tensorflow.log_model(model, \"mnist_tensorflow_{run_name}\", signature=signature)\n",
    "        \n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-27 14:55:42 +0300] [200190] [INFO] Starting gunicorn 21.2.0\n",
      "[2024-08-27 14:55:42 +0300] [200190] [INFO] Listening at: http://127.0.0.1:5000 (200190)\n",
      "[2024-08-27 14:55:42 +0300] [200190] [INFO] Using worker: sync\n",
      "[2024-08-27 14:55:42 +0300] [200195] [INFO] Booting worker with pid: 200195\n",
      "[2024-08-27 14:55:42 +0300] [200196] [INFO] Booting worker with pid: 200196\n",
      "[2024-08-27 14:55:42 +0300] [200197] [INFO] Booting worker with pid: 200197\n",
      "[2024-08-27 14:55:42 +0300] [200199] [INFO] Booting worker with pid: 200199\n",
      "2024/08/27 14:57:16 ERROR mlflow.server: Exception on /get-artifact [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 2190, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1486, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1484, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1469, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/__init__.py\", line 74, in serve_artifacts\n",
      "    return get_artifact_handler()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 566, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 633, in get_artifact_handler\n",
      "    return _send_artifact(artifact_repo, artifact_path)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 554, in _send_artifact\n",
      "    file_path = os.path.abspath(artifact_repository.download_artifacts(path))\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py\", line 91, in download_artifacts\n",
      "    raise OSError(f\"No such file or directory: '{local_artifact_path}'\")\n",
      "OSError: No such file or directory: '/home/sternade/Nextcloud_Kannu/Opari/mlruns/581032223001777713/6d31ed68e39146028e77e36048a4aebb/artifacts/model/serving_input_payload.json'\n",
      "2024/08/27 14:58:05 ERROR mlflow.server: Exception on /get-artifact [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 2190, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1486, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1484, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1469, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/__init__.py\", line 74, in serve_artifacts\n",
      "    return get_artifact_handler()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 566, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 633, in get_artifact_handler\n",
      "    return _send_artifact(artifact_repo, artifact_path)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 554, in _send_artifact\n",
      "    file_path = os.path.abspath(artifact_repository.download_artifacts(path))\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py\", line 91, in download_artifacts\n",
      "    raise OSError(f\"No such file or directory: '{local_artifact_path}'\")\n",
      "OSError: No such file or directory: '/home/sternade/Nextcloud_Kannu/Opari/mlruns/581032223001777713/6d31ed68e39146028e77e36048a4aebb/artifacts/model/serving_input_payload.json'\n",
      "2024/08/27 14:58:17 ERROR mlflow.server: Exception on /get-artifact [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 2190, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1486, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1484, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/flask/app.py\", line 1469, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/__init__.py\", line 74, in serve_artifacts\n",
      "    return get_artifact_handler()\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 566, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 633, in get_artifact_handler\n",
      "    return _send_artifact(artifact_repo, artifact_path)\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/server/handlers.py\", line 554, in _send_artifact\n",
      "    file_path = os.path.abspath(artifact_repository.download_artifacts(path))\n",
      "  File \"/home/sternade/.local/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py\", line 91, in download_artifacts\n",
      "    raise OSError(f\"No such file or directory: '{local_artifact_path}'\")\n",
      "OSError: No such file or directory: '/home/sternade/Nextcloud_Kannu/Opari/mlruns/581032223001777713/6d31ed68e39146028e77e36048a4aebb/artifacts/model/serving_input_payload.json'\n",
      "[2024-08-27 15:12:36 +0300] [200190] [CRITICAL] WORKER TIMEOUT (pid:200195)\n",
      "[2024-08-27 15:12:36 +0300] [200190] [CRITICAL] WORKER TIMEOUT (pid:200196)\n",
      "[2024-08-27 15:12:36 +0300] [200190] [CRITICAL] WORKER TIMEOUT (pid:200197)\n",
      "[2024-08-27 15:12:36 +0300] [200190] [CRITICAL] WORKER TIMEOUT (pid:200199)\n",
      "[2024-08-27 15:12:36 +0300] [200199] [INFO] Worker exiting (pid: 200199)\n",
      "[2024-08-27 15:12:36 +0300] [200197] [INFO] Worker exiting (pid: 200197)\n",
      "[2024-08-27 15:12:36 +0300] [200195] [INFO] Worker exiting (pid: 200195)\n",
      "[2024-08-27 15:12:36 +0300] [200196] [INFO] Worker exiting (pid: 200196)\n",
      "[2024-08-27 15:12:37 +0300] [200190] [ERROR] Worker (pid:200196) was sent SIGKILL! Perhaps out of memory?\n",
      "[2024-08-27 15:12:37 +0300] [203296] [INFO] Booting worker with pid: 203296\n",
      "[2024-08-27 15:12:37 +0300] [200190] [ERROR] Worker (pid:200199) was sent SIGKILL! Perhaps out of memory?\n",
      "[2024-08-27 15:12:37 +0300] [200190] [ERROR] Worker (pid:200197) was sent SIGKILL! Perhaps out of memory?\n",
      "[2024-08-27 15:12:37 +0300] [200190] [ERROR] Worker (pid:200195) was sent SIGKILL! Perhaps out of memory?\n",
      "[2024-08-27 15:12:38 +0300] [203297] [INFO] Booting worker with pid: 203297\n",
      "[2024-08-27 15:12:38 +0300] [203298] [INFO] Booting worker with pid: 203298\n",
      "[2024-08-27 15:12:38 +0300] [203299] [INFO] Booting worker with pid: 203299\n",
      "^C\n",
      "[2024-08-27 15:58:15 +0300] [200190] [INFO] Handling signal: int\n",
      "[2024-08-27 15:58:15 +0300] [203296] [INFO] Worker exiting (pid: 203296)\n",
      "[2024-08-27 15:58:15 +0300] [203298] [INFO] Worker exiting (pid: 203298)\n",
      "[2024-08-27 15:58:15 +0300] [203297] [INFO] Worker exiting (pid: 203297)\n",
      "[2024-08-27 15:58:15 +0300] [203299] [INFO] Worker exiting (pid: 203299)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tässä välissä kurkataan UIn puolella ja esitellään niitä ominaisuuksia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_2 = Sequential(\n",
    "    [\n",
    "        model_2.add(Flatten(input_shape=(28, 28))),\n",
    "        model_2.add(Dense(128, activation='tanh')),\n",
    "        model_2.add(Dense(64, activation='tanh')),\n",
    "        model_2.add(Dense(10, activation='softmax'))\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
